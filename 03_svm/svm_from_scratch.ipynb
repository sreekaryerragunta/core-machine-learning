{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SVM From Scratch - Simplified\n",
                "\n",
                "Demonstrating SVM concepts using sklearn (full from-scratch implementation requires complex optimization).\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn import datasets\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "sns.set_style('darkgrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Linear SVM on Separable Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate linearly separable data\n",
                "from sklearn.datasets import make_blobs\n",
                "X, y = make_blobs(n_samples=100, centers=2, random_state=42, cluster_std=0.8)\n",
                "\n",
                "# Train linear SVM\n",
                "svm = SVC(kernel='linear', C=1.0)\n",
                "svm.fit(X, y)\n",
                "\n",
                "# Get support vectors\n",
                "support_vectors = svm.support_vectors_\n",
                "\n",
                "print(f'Number of support vectors: {len(support_vectors)}')\n",
                "print(f'Accuracy: {svm.score(X, y)*100:.2f}%')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize decision boundary\n",
                "def plot_svm_boundary(svm, X, y, title):\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    \n",
                "    # Create mesh\n",
                "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
                "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
                "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
                "                         np.linspace(y_min, y_max, 200))\n",
                "    \n",
                "    # Predict\n",
                "    Z = svm.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
                "    Z = Z.reshape(xx.shape)\n",
                "    \n",
                "    # Plot decision boundary and margins\n",
                "    plt.contourf(xx, yy, Z, levels=[-1, 0, 1], alpha=0.3, colors=['red', 'blue'])\n",
                "    plt.contour(xx, yy, Z, levels=[-1, 0, 1], linewidths=[1, 2, 1],\n",
                "               linestyles=['--', '-', '--'], colors='black')\n",
                "    \n",
                "    # Plot data points\n",
                "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', edgecolors='k', s=50)\n",
                "    \n",
                "    # Highlight support vectors\n",
                "    plt.scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1],\n",
                "               s=200, linewidth=2, facecolors='none', edgecolors='green',\n",
                "               label='Support Vectors')\n",
                "    \n",
                "    plt.xlabel('Feature 1', fontsize=12)\n",
                "    plt.ylabel('Feature 2', fontsize=12)\n",
                "    plt.title(title, fontsize=14, fontweight='bold')\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "\n",
                "plot_svm_boundary(svm, X, y, 'Linear SVM with Maximum Margin')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Effect of C Parameter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add some noise\n",
                "X_noise, y_noise = make_blobs(n_samples=100, centers=2, random_state=42, cluster_std=1.5)\n",
                "\n",
                "C_values = [0.01, 1, 100]\n",
                "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
                "\n",
                "for idx, C in enumerate(C_values):\n",
                "    svm_c = SVC(kernel='linear', C=C)\n",
                "    svm_c.fit(X_noise, y_noise)\n",
                "    \n",
                "    # Create mesh\n",
                "    x_min, x_max = X_noise[:, 0].min() - 1, X_noise[:, 0].max() + 1\n",
                "    y_min, y_max = X_noise[:, 1].min() - 1, X_noise[:, 1].max() + 1\n",
                "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
                "                         np.linspace(y_min, y_max, 200))\n",
                "    \n",
                "    Z = svm_c.decision_function(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
                "    \n",
                "    axes[idx].contourf(xx, yy, Z, alpha=0.3, cmap=' RdYlBu')\n",
                "    axes[idx].contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n",
                "    axes[idx].scatter(X_noise[:, 0], X_noise[:, 1], c=y_noise, cmap='RdYlBu',\n",
                "                     edgecolors='k', s=50)\n",
                "    axes[idx].scatter(svm_c.support_vectors_[:, 0], svm_c.support_vectors_[:, 1],\n",
                "                     s=200, facecolors='none', edgecolors='green', linewidth=2)\n",
                "    \n",
                "    axes[idx].set_title(f'C={C} ({len(svm_c.support_vectors_)} SVs)',\n",
                "                       fontsize=13, fontweight='bold')\n",
                "    axes[idx].set_xlabel('Feature 1')\n",
                "    axes[idx].set_ylabel('Feature 2')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('Low C → more support vectors, larger margin')\n",
                "print('High C → fewer support vectors, smaller margin')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "### Key Insights:\n",
                "- SVM finds maximum margin hyperplane\n",
                "- Only support vectors matter\n",
                "- C controls margin vs violations trade-off\n",
                "- Green circles show support vectors\n",
                "\n",
                "### Key Point:\n",
                "\"SVM finds the hyperplane that maximizes the margin to the nearest points (support vectors). Parameter C balances margin width against classification errors.\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}