{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Feature Importance Analysis\n",
                "\n",
                "Understanding which features matter most in Random Forests:\n",
                "1. Calculate feature importance\n",
                "2. Visualize importance scores\n",
                "3. Compare with sklearn\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import load_iris, make_classification\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "from decision_trees.tree_from_scratch import DecisionTree\n",
                "from utils import bootstrap_sample, majority_vote\n",
                "\n",
                "sns.set_style('darkgrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Load Iris Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iris = load_iris()\n",
                "X = iris.data\n",
                "y = iris.target\n",
                "feature_names = iris.feature_names\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f'Dataset: {X.shape}')\n",
                "print(f'Features: {feature_names}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Feature Importance with Scikit-Learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Random Forest\n",
                "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
                "rf.fit(X_train, y_train)\n",
                "\n",
                "# Get feature importance\n",
                "importances = rf.feature_importances_\n",
                "\n",
                "# Sort by importance\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "print('='*60)\n",
                "print('FEATURE IMPORTANCE')\n",
                "print('='*60)\n",
                "for i in range(len(feature_names)):\n",
                "    idx = indices[i]\n",
                "    print(f'{i+1}. {feature_names[idx]:25s}: {importances[idx]:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Visualize Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create bar plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.bar(range(len(importances)), importances[indices], \n",
                "        color='steelblue', edgecolor='black')\n",
                "plt.xticks(range(len(importances)), \n",
                "          [feature_names[i] for i in indices], rotation=45, ha='right')\n",
                "plt.xlabel('Features', fontsize=12)\n",
                "plt.ylabel('Importance Score', fontsize=12)\n",
                "plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3, axis='y')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpretation\n",
                "\n",
                "Features are ranked by how much they reduce impurity across all trees.\n",
                "\n",
                "**For Iris Dataset**:\n",
                "- **Petal length** and **petal width** are most important\n",
                "- These features best separate the three Iris species\n",
                "- Sepal measurements are less discriminative"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Create Synthetic Dataset with Known Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create dataset where features have different importance\n",
                "n_samples = 1000\n",
                "X_syn = np.random.randn(n_samples, 5)\n",
                "\n",
                "# y depends strongly on X[:, 0] and X[:, 1], weakly on X[:, 2], not on X[:, 3] or X[:, 4]\n",
                "y_syn = (3 * X_syn[:, 0] + 2 * X_syn[:, 1] + 0.5 * X_syn[:, 2] + \n",
                "         np.random.randn(n_samples) * 0.1)\n",
                "y_syn = (y_syn > np.median(y_syn)).astype(int)\n",
                "\n",
                "print('True feature importance (by construction):')\n",
                "print('Feature 0: HIGH (coef=3.0)')\n",
                "print('Feature 1: HIGH (coef=2.0)') \n",
                "print('Feature 2: LOW (coef=0.5)')\n",
                "print('Feature 3: NONE (random noise)')\n",
                "print('Feature 4: NONE (random noise)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Random Forest\n",
                "rf_syn = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_syn.fit(X_syn, y_syn)\n",
                "\n",
                "# Get importance\n",
                "imp_syn = rf_syn.feature_importances_\n",
                "\n",
                "# Visualize\n",
                "plt.figure(figsize=(10, 6))\n",
                "colors = ['green', 'green', 'orange', 'red', 'red']\n",
                "plt.bar(range(5), imp_syn, color=colors, edgecolor='black', alpha=0.7)\n",
                "plt.xticks(range(5), [f'Feature {i}' for i in range(5)])\n",
                "plt.xlabel('Features', fontsize=12)\n",
                "plt.ylabel('Importance Score', fontsize=12)\n",
                "plt.title('Feature Importance on Synthetic Data', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3, axis='y')\n",
                "plt.legend(['Important', 'Somewhat Important', 'Noise'], loc='upper right')\n",
                "plt.show()\n",
                "\n",
                "print('\\nLearned Feature Importance:')\n",
                "for i in range(5):\n",
                "    print(f'Feature {i}: {imp_syn[i]:.4f}')\n",
                "\n",
                "print('\\nObservation: Random Forest correctly identifies important features!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "### Feature Importance Benefits:\n",
                "1. **Feature selection**: Remove unimportant features\n",
                "2. **Model interpretation**: Understand what drives predictions\n",
                "3. **Domain insight**: Validate assumptions about data\n",
                "4. **Debugging**: Identify unexpected feature influence\n",
                "\n",
                "### How It Works:\n",
                "- **Mean Decrease in Impurity**: Sum of impurity reduction across all splits using that feature\n",
                "- **Normalized**: Scores sum to 1.0\n",
                "- **Higher score**: Feature is more important for predictions\n",
                "\n",
                "### Key Point:\n",
                "\"Random Forests automatically calculate feature importance by measuring how much each feature reduces impurity across all trees and splits. Features that frequently reduce impurity (create purer child nodes) are more important. This provides interpretability without sacrificing predictive power.\"\n",
                "\n",
                "---\n",
                "\n",
                "**Random Forests component complete!**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}